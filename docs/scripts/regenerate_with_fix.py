#!/usr/bin/env python3
"""
Regenerate Spark code with fixed Jinja2 template
"""
import sys
import os
from pathlib import Path
sys.path.insert(0, 'src')

# Import the necessary components
from core.xml_parser import InformaticaXMLParser
from core.spark_code_generator import SparkCodeGenerator

def main():
    print("üîß Regenerating Spark Application with Fixed Template")
    print("=" * 55)
    
    # Parse the XML file
    print("üìÑ Parsing XML file: input/complex_production_project.xml")
    parser = InformaticaXMLParser()
    
    try:
        project = parser.parse_project("input/complex_production_project.xml")
        print(f"‚úÖ Successfully parsed project: {project.name}")
    except Exception as e:
        print(f"‚ùå Error parsing XML: {e}")
        return
    
    # Generate the Spark application
    output_dir = "generated_spark_app/ALIGNMENT_FIXED_TEST"
    print(f"üöÄ Generating Spark application to: {output_dir}")
    
    try:
        generator = SparkCodeGenerator()
        generator.generate_spark_application(project, output_dir)
        print("‚úÖ Spark application generated successfully!")
        
        # Check the generated mapping file
        mapping_file = Path(output_dir) / "src/main/python/mappings/m_process_customer_data.py"
        if mapping_file.exists():
            print(f"\nüìã Generated mapping file: {mapping_file}")
            print("üìÑ First 35 lines of generated code:")
            
            with open(mapping_file, 'r') as f:
                lines = f.readlines()
                
            for i, line in enumerate(lines[:35], 1):
                print(f"{i:3d}‚Üí{line.rstrip()}")
                
            # Quick alignment check
            problematic_lines = []
            for i, line in enumerate(lines, 1):
                # Check for the specific issue we fixed
                if line.strip().startswith('self.logger.info("Starting') and len(line.strip()) > 100:
                    problematic_lines.append(i)
                elif ('_df = self._read_' in line and 'current_df =' in line):
                    problematic_lines.append(i)
                    
            if problematic_lines:
                print(f"\n‚ùå Still found alignment issues on lines: {problematic_lines}")
            else:
                print(f"\n‚úÖ No obvious alignment issues detected!")
                
        else:
            print(f"‚ùå Generated mapping file not found at: {mapping_file}")
            
    except Exception as e:
        print(f"‚ùå Error generating Spark application: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()