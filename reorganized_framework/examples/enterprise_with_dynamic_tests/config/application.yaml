connections:
  ENTERPRISE_HDFS_CONN:
    BlockSize: 128MB
    EncryptionEnabled: 'true'
    ReplicationFactor: '3'
    SecurityEnabled: 'true'
    description: Enterprise HDFS cluster connection
    format: parquet
    host: ''
    namenode: hdfs://enterprise-cluster:8020
    port: 0
    type: HDFS
    '{http://com.informatica.imx}id': CONN_002
    '{http://www.w3.org/2001/XMLSchema-instance}type': HDFSConnectinfo
  ENTERPRISE_HIVE_CONN:
    ConnectionTimeout: '600'
    EnableSSL: 'true'
    Kerberos: enabled
    MaxConnections: '50'
    Principal: hive/_HOST@ENTERPRISE.LOCAL
    TransactionIsolation: READ_COMMITTED
    database: enterprise_edw
    description: Enterprise Hive data warehouse with HA configuration
    driver: org.apache.hive.jdbc.HiveDriver
    format: hive
    host: hive-ha-cluster.enterprise.local
    port: 10000
    type: HIVE
    url: jdbc:hive2://hive-ha-cluster.enterprise.local:10000/enterprise_edw
    '{http://com.informatica.imx}id': CONN_001
    '{http://www.w3.org/2001/XMLSchema-instance}type': Hive:HiveConnectinfo
log_level: INFO
parameters: {}
spark:
  spark.app.name: Enterprise_Complete_Transformations
  spark.master: local[*]
  spark.sql.adaptive.coalescePartitions.enabled: 'true'
  spark.sql.adaptive.enabled: 'true'
  spark.sql.warehouse.dir: ./spark-warehouse
